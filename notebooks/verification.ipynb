{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "\n",
    "from decisiontree.dt_goal_recogniser import HandcraftedGoalTrees, TrainedDecisionTrees\n",
    "from evaluation.verification import add_goal_tree_model, extract_counter_example\n",
    "from core.data_processing import get_dataset\n",
    "from core.feature_extraction import FeatureExtractor\n",
    "from core.scenario import ScenarioConfig, Scenario\n",
    "from core.base import get_data_dir, get_scenario_config_dir, get_img_dir\n",
    "from core.lanelet_helpers import LaneletHelpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handcrafted goal tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsat\n"
     ]
    }
   ],
   "source": [
    "scenario_name = 'heckstrasse'\n",
    "model = HandcraftedGoalTrees.load(scenario_name)\n",
    "reachable_goals = [(1, 'straight-on'), (2, 'turn-left')]\n",
    "\n",
    "s = Solver()\n",
    "\n",
    "features, probs = add_goal_tree_model(reachable_goals, s, model)\n",
    "\n",
    "# unsatisfiable if G2 always has highest prob\n",
    "verify_expr = Implies(And(features[1]['in_correct_lane'], Not(features[2]['in_correct_lane'])), probs[2] < probs[1])\n",
    "s.add(Not(verify_expr))\n",
    "\n",
    "print(s.check())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verified true:\n",
    "If car is in correct lane for G1, then G1 is predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsat\n"
     ]
    }
   ],
   "source": [
    "scenario_name = 'heckstrasse'\n",
    "model = HandcraftedGoalTrees.load(scenario_name)\n",
    "reachable_goals = [(1, 'straight-on'), (2, 'turn-left')]\n",
    "\n",
    "s = Solver()\n",
    "\n",
    "features, probs = add_goal_tree_model(reachable_goals, s, model)\n",
    "\n",
    "verify_expr = Implies(And(Not(features[1]['in_correct_lane']),\n",
    "                          features[2]['in_correct_lane']), probs[2] > probs[1])\n",
    "s.add(Not(verify_expr))\n",
    "\n",
    "print(s.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verified true:\n",
    "If car is in correct lane for G2, G2 is predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained goal tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sat\n"
     ]
    }
   ],
   "source": [
    "scenario_name = 'heckstrasse'\n",
    "model = TrainedDecisionTrees.load(scenario_name)\n",
    "reachable_goals = [(1, 'straight-on'), (2, 'turn-left')]\n",
    "\n",
    "s = Solver()\n",
    "\n",
    "features, probs = add_goal_tree_model(reachable_goals, s, model)\n",
    "\n",
    "verify_expr = Implies(And(features[1]['in_correct_lane'],\n",
    "                          Not(features[2]['in_correct_lane'])),\n",
    "                      probs[2] < probs[1])\n",
    "s.add(Not(verify_expr))\n",
    "\n",
    "print(s.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[likelihood_1_straight-on = 3328868578632209/62500000000000000,\n",
       " angle_in_lane_1 = 1/32,\n",
       " likelihood_2_turn-left = 4733690513709423/5000000000000000,\n",
       " path_to_goal_length_2 = 611815071105957/10000000000000,\n",
       " acceleration_1 = 183992999792099/200000000000000,\n",
       " path_to_goal_length_1 = 783497200012207/10000000000000,\n",
       " in_correct_lane_2 = False,\n",
       " in_correct_lane_1 = True,\n",
       " prob_2_turn-left = 69741296702901268516935306473415/92669415458121270862886033690107,\n",
       " prob_1_straight-on = 22928118755220002345950727216692/92669415458121270862886033690107,\n",
       " vehicle_in_front_speed_1 = 0,\n",
       " vehicle_in_front_speed_2 = 0,\n",
       " vehicle_in_front_speed = 0,\n",
       " vehicle_in_front_dist_1 = 0,\n",
       " vehicle_in_front_dist_2 = 0,\n",
       " vehicle_in_front_dist = 0,\n",
       " angle_in_lane_2 = 1/32,\n",
       " angle_in_lane = 1/32,\n",
       " acceleration_2 = 183992999792099/200000000000000,\n",
       " acceleration = 183992999792099/200000000000000,\n",
       " speed_1 = 0,\n",
       " speed_2 = 0,\n",
       " speed = 0,\n",
       " /0 = [(41844778021740761110161183884049/500000000000000000000000000000000,\n",
       "       278008246374363812588658101070321/2500000000000000000000000000000000) &rarr;\n",
       "      69741296702901268516935306473415/92669415458121270862886033690107,\n",
       "      (17196089066415001759463045412519/625000000000000000000000000000000,\n",
       "       278008246374363812588658101070321/2500000000000000000000000000000000) &rarr;\n",
       "      22928118755220002345950727216692/92669415458121270862886033690107,\n",
       "      else &rarr; 0]]"
      ],
      "text/plain": [
       "[likelihood_1_straight-on = 3328868578632209/62500000000000000,\n",
       " angle_in_lane_1 = 1/32,\n",
       " likelihood_2_turn-left = 4733690513709423/5000000000000000,\n",
       " path_to_goal_length_2 = 611815071105957/10000000000000,\n",
       " acceleration_1 = 183992999792099/200000000000000,\n",
       " path_to_goal_length_1 = 783497200012207/10000000000000,\n",
       " in_correct_lane_2 = False,\n",
       " in_correct_lane_1 = True,\n",
       " prob_2_turn-left = 69741296702901268516935306473415/92669415458121270862886033690107,\n",
       " prob_1_straight-on = 22928118755220002345950727216692/92669415458121270862886033690107,\n",
       " vehicle_in_front_speed_1 = 0,\n",
       " vehicle_in_front_speed_2 = 0,\n",
       " vehicle_in_front_speed = 0,\n",
       " vehicle_in_front_dist_1 = 0,\n",
       " vehicle_in_front_dist_2 = 0,\n",
       " vehicle_in_front_dist = 0,\n",
       " angle_in_lane_2 = 1/32,\n",
       " angle_in_lane = 1/32,\n",
       " acceleration_2 = 183992999792099/200000000000000,\n",
       " acceleration = 183992999792099/200000000000000,\n",
       " speed_1 = 0,\n",
       " speed_2 = 0,\n",
       " speed = 0,\n",
       " /0 = [(41844778021740761110161183884049/500000000000000000000000000000000,\n",
       "        278008246374363812588658101070321/2500000000000000000000000000000000) ->\n",
       "       69741296702901268516935306473415/92669415458121270862886033690107,\n",
       "       (17196089066415001759463045412519/625000000000000000000000000000000,\n",
       "        278008246374363812588658101070321/2500000000000000000000000000000000) ->\n",
       "       22928118755220002345950727216692/92669415458121270862886033690107,\n",
       "       else -> 0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1e0678a99050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_counter_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/phd/projects/av-goal-recognition/evaluation/verification.py\u001b[0m in \u001b[0;36mextract_counter_example\u001b[0;34m(solver, features)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mfeature_values_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'goal_idx'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgoal_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feature'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "extract_counter_example(s, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G1\n",
    "22928118755220002345950727216692/76318343603113298254273810502177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G2\n",
    "53390224847893295908323083285485/76318343603113298254273810502177"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification failed: If car is in correct lane for G1, then G1 is predicted.\n",
    "Angle in lane > 0.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate examples of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"../images/trained_tree_heckstrasse_G1_straight-on.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"../images/trained_tree_heckstrasse_G2_turn-left.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(scenario_name, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = Scenario.load(get_scenario_config_dir() + '{}.json'.format(scenario_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor(scenario.lanelet_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = scenario.load_episode(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = episode.frames[8292].agents[114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_routes = feature_extractor.get_goal_routes(state, scenario.config.goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "scenario.plot()\n",
    "LaneletHelpers.plot(goal_routes[1].shortestPath()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "scenario.plot()\n",
    "LaneletHelpers.plot(goal_routes[2].shortestPath()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[(dataset.in_correct_lane)  \n",
    "            & (dataset.angle_in_lane > 0.05)\n",
    "           & (dataset.possible_goal==1) & (dataset.goal_type=='straight-on')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasons for wrong lane:\n",
    "1. Start of trajectory, has not yet changed lane\n",
    "\n",
    "heckstrasse agent 114 frame 8292 get current lanelet?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'heckstrasse'\n",
    "model = TrainedDecisionTrees.load(scenario_name)\n",
    "reachable_goals = [(1, 'straight-on'), (2, 'turn-left')]\n",
    "\n",
    "s = Solver()\n",
    "\n",
    "features, probs = add_goal_tree_model(reachable_goals, s, model)\n",
    "\n",
    "\n",
    "verify_expr = Implies(And(Not(features[1]['in_correct_lane']), features[2]['in_correct_lane']), probs[2] > probs[1])\n",
    "s.add(Not(verify_expr))\n",
    "\n",
    "print(s.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verified true: If car is in correct lane for G2, G2 is predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify bound on probability if in the correct lane\n",
    "If we are in the correct lane for a goal, the the probabilty of that goal should be > 0.2\n",
    "Heckstrasse - coming from west"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'heckstrasse'\n",
    "model = TrainedDecisionTrees.load(scenario_name)\n",
    "reachable_goals = [(1, 'straight-on'), (2, 'turn-left')]\n",
    "\n",
    "s = Solver()\n",
    "\n",
    "features, probs = add_goal_tree_model(reachable_goals, s, model)\n",
    "\n",
    "\n",
    "verify_expr = Implies(And(features[1]['in_correct_lane'],\n",
    "                          Not(features[2]['in_correct_lane'])), probs[1] >= 0.2)\n",
    "s.add(Not(verify_expr))\n",
    "\n",
    "print(s.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'heckstrasse'\n",
    "model = TrainedDecisionTrees.load(scenario_name)\n",
    "reachable_goals = [(1, 'straight-on'), (2, 'turn-left')]\n",
    "\n",
    "s = Solver()\n",
    "\n",
    "features, probs = add_goal_tree_model(reachable_goals, s, model)\n",
    "\n",
    "\n",
    "verify_expr = Implies(And(Not(features[1]['in_correct_lane']),\n",
    "                          features[2]['in_correct_lane']), probs[2] >= 0.2)\n",
    "s.add(Not(verify_expr))\n",
    "\n",
    "print(s.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both goals, this is verified to be true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify prob based on angle in lane, approaching T Junction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'heckstrasse'\n",
    "model = TrainedDecisionTrees.load(scenario_name)\n",
    "reachable_goals = [(0, 'turn-right'), (1, 'turn-left')]\n",
    "\n",
    "s = Solver()\n",
    "\n",
    "features, probs = add_goal_tree_model(reachable_goals, s, model)\n",
    "\n",
    "s.add(features[0]['angle_in_lane'] >= np.pi / 8)\n",
    "s.add(features[1]['angle_in_lane'] >= np.pi / 8)\n",
    "\n",
    "verify_expr =  probs[1] >= 0.1\n",
    "s.add(Not(verify_expr))\n",
    "\n",
    "print(s.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2346984033116499/62500000000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "52939762064801009122130908858125/55512532424702459568794311420649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2572770359901450446663402562524/55512532424702459568794311420649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"../images/trained_tree_heckstrasse_G0_turn-right.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2346984033116499/62500000000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"../images/trained_tree_heckstrasse_G1_turn-left.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6231454005934719/10000000000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.goal_priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify that decreasing path to goal length leads to decreasing entropy\n",
    "Can easily be done when there are two goals\n",
    "Start with heckstrasse approaching from west"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'heckstrasse'\n",
    "model = TrainedDecisionTrees.load(scenario_name)\n",
    "reachable_goals = [(1, 'straight-on'), (2, 'turn-left')]\n",
    "\n",
    "s = Solver()\n",
    "\n",
    "# 2 has shorter path to goal length than 1, but all other features are equal\n",
    "features1, probs1 = add_goal_tree_model(reachable_goals, s, model, suffix='_1')\n",
    "features2, probs2 = add_goal_tree_model(reachable_goals, s, model, suffix='_2')\n",
    "\n",
    "for goal_idx, goal_type in reachable_goals:\n",
    "    s.add(features1[goal_idx]['path_to_goal_length'] \\\n",
    "          > features2[goal_idx]['path_to_goal_length'])\n",
    "    \n",
    "    for feature_name in features1[goal_idx]:\n",
    "        if feature_name != 'path_to_goal_length':\n",
    "            s.add(features1[goal_idx][feature_name] == features2[goal_idx][feature_name])\n",
    "\n",
    "\n",
    "verify_expr = And(Implies(probs1[1] < probs1[2], probs2[2] >= probs1[2]), \n",
    "                  Implies(probs1[1] > probs1[2], probs2[1] >= probs1[1]))\n",
    "\n",
    "s.add(Not(verify_expr))\n",
    "\n",
    "\n",
    "print(s.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verification failed\n",
    "Counterexample:\n",
    "path_to_goal_length_1_1 = -1/4\n",
    "path_to_goal_length_1_2 = -2\n",
    "\n",
    "This features caused the difference:\n",
    "path_to_goal_length_2_1 = 62\n",
    "path_to_goal_length_2_2 = 59\n",
    "\n",
    "likelihood_2_turn-left_1 = 0.032\n",
    "likelihood_2_turn-left_2 = 0.002\n",
    "\n",
    "likelihood_1_straight-on_1 = 0.0003\n",
    "likelihood_1_straight-on_2 = 0.0003\n",
    "\n",
    "in_correct_lane is false for both goals - should not be possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_2_turn_left_2 = 12985641854098344188989774327125/24583179829227809648801218976353\n",
    "prob_1_straight_on_2 = 11597537975129465459811444649228/24583179829227809648801218976353\n",
    "prob_2_turn_left_1 = 46699757191188387508825432121897/49599141684970753873778293284204\n",
    "prob_1_straight_on_1 = 2899384493782366364952861162307/49599141684970753873778293284204\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prob_1_straight_on_1)\n",
    "print(prob_1_straight_on_2)\n",
    "print(prob_2_turn_left_1)\n",
    "print(prob_2_turn_left_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1683813668581631/5000000000000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try verification again, restricting feature values based on domain knowledge\n",
    "\n",
    "Eventually domain model / feature extraction could be represented in logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'heckstrasse'\n",
    "model = TrainedDecisionTrees.load(scenario_name)\n",
    "reachable_goals = [(1, 'straight-on'), (2, 'turn-left')]\n",
    "\n",
    "s = Solver()\n",
    "\n",
    "# 2 has shorter path to goal length than 1, but all other features are equal\n",
    "features1, probs1 = add_goal_tree_model(reachable_goals, s, model, suffix='_1')\n",
    "features2, probs2 = add_goal_tree_model(reachable_goals, s, model, suffix='_2')\n",
    "\n",
    "for goal_idx, goal_type in reachable_goals:\n",
    "    s.add(features1[goal_idx]['path_to_goal_length'] \\\n",
    "          > features2[goal_idx]['path_to_goal_length'])\n",
    "    \n",
    "    for feature_name in features1[goal_idx]:\n",
    "        if feature_name != 'path_to_goal_length':\n",
    "            s.add(features1[goal_idx][feature_name] == features2[goal_idx][feature_name])\n",
    "\n",
    "s.add(features1[1]['in_correct_lane'] != features1[2]['in_correct_lane'])\n",
    "\n",
    "            \n",
    "verify_expr = And(Implies(probs1[1] < probs1[2], probs2[2] == probs1[2]), \n",
    "                  Implies(probs1[1] > probs1[2], probs2[1] == probs1[1]))\n",
    "\n",
    "s.add(Not(verify_expr))\n",
    "\n",
    "\n",
    "print(s.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_2_turn_left_2 = 35256017633877/16000000000000000\n",
    "likelihood_1_straight_on_2 = 28828658074298713/100000000000000000\n",
    "likelihood_2_turn_left_1 = 15848730096759557/500000000000000000\n",
    "likelihood_1_straight_on_1 = 28828658074298713/100000000000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(likelihood_1_straight_on_1)\n",
    "print(likelihood_1_straight_on_2)\n",
    "print(likelihood_2_turn_left_1)\n",
    "print(likelihood_2_turn_left_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not verified - different child node reached  depending path to goal length\n",
    "When further from goal, acceleration is informative - high acceleration means lower G2 likelihood\n",
    "\n",
    "Looks like overfitting - see tree below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('../images/trained_tree_heckstrasse_G2_turn-left.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
